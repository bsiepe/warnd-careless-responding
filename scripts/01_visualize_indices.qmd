---
title: "Online Supplement 1: Visualizing Indices"
subtitle: "For the Manuscript: Identifying Careless Responding in Ecological Momentary Assessment: Inconsistent Signals from Different Detection Methods in the WARN-D Data"
author: 
 - name: Björn S. Siepe
   orcid: 0000-0002-9558-4648
   affiliations: University of Marburg
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    number-sections: true
    theme: cosmo
    code-fold: true
    code-tools: true
    code-summary: "Show the code"
    fig-width: 8
    fig-height: 5
    fig-align: "center"
    embed-resources: true
execute:
  message: false
  warning: false
  eval: true # run code?
params:
  rerun: false  # define parameter if all large analyses should be rerun
---

# Background

In this document, we visualize and analyze all indices that were computed in `01_calculate_indices.qmd`. 

We first load all relevant packages: 
```{r packages}
if(!require(pacman))
  install.packages("pacman")
pacman::p_load(
  "here",
  "ggplot2",
  "rrcov",
  "Hmisc",
  "sysfonts",
  "showtext",
  "ggh4x",
  "cowplot",
  "gtsummary",
  "gt",
  "future",
  "furrr",
  "dplyr",
  "tidyr",
  "vegan",
  "tibble",
  "purrr",
  "flextable",
  "patchwork"
)

source(here("scripts", "00_functions.R"))

# use color based on the Johnson palette from MetBrewer
fill_color <- "#132b69"

set.seed(35032)  
```


Relevant EMA items and their reaction times: 
```{r ema-itemss}
ema_items <-  c("sad_d", "stressed_d", "overwhelm_d", "nervous_d", "ruminate_d", "irritable_d", "cheerful_d", "motivated_d", "relaxed_d")
rt_ema_items <- paste0("rt_", ema_items)
```


For later visualizations, we also load the results of different model-based approaches: 
```{r load-models}
lpa_res <- readRDS(here::here("output", "data_profiles_corrected.RDS"))
irt_res <- readRDS(here::here("output", "data_mixtureIRT.RDS"))
```


# Descriptives & Visualizations

In this section, we describe and visualize our results.

## Summary statistics
Numbers in parentheses represent first and third quartiles. 
```{r}
df_indices <- readRDS(here::here("output", "df_indices.RDS"))
df_indices |>   
  mutate(k_values = as.factor(k_values), 
         anto_violations = as.factor(anto_violations), 
         longstring_count = as.factor(longstring_count)) |> 
  gtsummary::tbl_summary(include = !c(external_id, counter),
                       missing_text = "(Missing)") |> 
  gtsummary::as_gt()
```


## Main cutoffs

Above, we defined the main default cutoffs that we use for the paper. We now check how many responses are marked as careless for each of the indices (in percent of all responses). Please note that we obtain slightly different percentages (second decimal difference) to the results in @sec-overview-indices. This difference occurs due to the way in which missing values are recorded. Here, we calculate them based on the within-assessment SD - below, we calculate them based on the missings for each individual careless response flag. For the overview in the manuscript, we keep it as it is here. 
```{r}
flag_df <- readRDS(here::here("output", "flag_df.RDS"))

total_obs <- nrow(flag_df)
non_missing_obs <- flag_df |> 
  filter(!is.na(flag_sd_within)) |> 
  nrow()

flag_df |> 
  ungroup() |> 
  select(!c(external_id, counter, flag_sum)) |> 
  summarize(across(everything(), 
                   ~sum(., na.rm = TRUE))) |> 
  mutate(across(everything(), 
                ~ round(./ non_missing_obs * 100, 3))) |> 
  knitr::kable()
```



What happens when using the multiple-hurdle approach with these indices? We again check how many responses are marked as careless for each of the approaches (in percent of all responses). 
```{r}
df_jaccard_spec <- readRDS(here::here("output", "df_jaccard_spec.RDS"))
df_jaccard_spec |> 
    filter(
    sd_within_cutoff == 1.25 &
      average_response_time_cutoff == 2 &
      sd_response_time_cutoff == 1 &
      longstring_cutoff == 7 & mode_cutoff == 5
  ) |> 
  mutate(across(contains("n_"),
                ~ round(./ non_missing_obs * 100, 2))) |> 
  rename(
    "Prop. Careless Single Hurdle" = n_careless_sum1, 
    "Prop. Careless Double Hurdle" = n_careless_sum2
  ) |> 
  knitr::kable()
```

How would these change if we slightly changed one cutoff, e.g., the SD response time cutoff to 0.6?
```{r}
#| label: change-sd-cutoff

df_jaccard_spec <- readRDS(here::here("output", "df_jaccard_spec.RDS"))
df_jaccard_spec |> 
    filter(
    sd_within_cutoff == 1.25 &
      average_response_time_cutoff == 2 &
      sd_response_time_cutoff == 1 &
      longstring_cutoff == 7 & mode_cutoff == 6
  ) |> 
  mutate(across(contains("n_"),
                ~ round(./ non_missing_obs * 100, 2))) |> 
  rename(
    "Prop. Careless Single Hurdle" = n_careless_sum1, 
    "Prop. Careless Double Hurdle" = n_careless_sum2
  ) |> 
  knitr::kable()
```


### Comparison to Sensitivity Cutoffs

Above, we also defined some cutoffs for sensitivity checks. We chose the most lenient cutoffs. 
Which percentage of careless responding do these indicate?

```{r}
#| label: sensitivity-cutoffs

lenient_flag_df <- readRDS(here::here("output", "lenient_flag_df.RDS"))
lenient_flag_df |> 
  ungroup() |> 
  select(!c(external_id, counter)) |> 
  mutate(flag_sum1 = ifelse(flag_sum == 0, 0, 1),
          flag_sum2 = ifelse(flag_sum <2, 0, 1)) |> 
  summarize(across(everything(), 
                   ~sum(., na.rm = TRUE))) |> 
  mutate(across(everything(), 
                ~ round(./ non_missing_obs * 100, 3))) |> 
  knitr::kable()

```


## Overview over all single-index cutoffs {#sec-overview-indices}

Here, we provide an overview over the proportion of responses flagged as careless for each individual index cutoff:
```{r}
#| label: index-overview-table
# cutoff values for each index
cutoffs <- list(
  sd_within = c(0.75, 1, 1.25),
  avg_rt = c(1, 1.5, 2),
  sd_rt = c(0.4, 0.6, 1),
  longstring = c(6, 7, 8),
  mode = c(5, 6),
  anto = c(0)
)

# calculate proportions for each index
results <- map_dfr(names(cutoffs), function(index_name) {
  cutoff_values <- cutoffs[[index_name]]
  
  # determine the column name and comparison operator
  col_name <- case_when(
    index_name == "sd_within" ~ "assessment_sd",
    index_name == "avg_rt" ~ "average_response_time", 
    index_name == "sd_rt" ~ "sd_response_time",
    index_name == "longstring" ~ "longstring_count",
    index_name == "mode" ~ "mode_count",
    index_name == "anto" ~ "anto_violations"
  )
  
  # calculate proportions for each cutoff
  props <- map_dbl(cutoff_values, function(cutoff) {
    valid_n <- sum(!is.na(df_indices[[col_name]]))
    if (index_name %in% c("longstring", "mode", "anto")) {
      sum(df_indices[[col_name]] > cutoff, na.rm = TRUE) / valid_n
    } else {
      sum(df_indices[[col_name]] < cutoff, na.rm = TRUE) / valid_n
    }
  })
  
  # create a tibble with proper column names
  result <- tibble(index = index_name)
  for (i in seq_along(cutoff_values)) {
    col_name <- paste0(index_name, "_", cutoff_values[i])
    result[[col_name]] <- props[i]
  }
  
  result
})

clean_table_long <- results |>
  rowwise() |>
  mutate(
    cutoff_values = case_when(
      index == "sd_within" ~ list(c(sd_within_0.75, sd_within_1, sd_within_1.25)),
      index == "avg_rt" ~ list(c(avg_rt_1, avg_rt_1.5, avg_rt_2)),
      index == "sd_rt" ~ list(c(sd_rt_0.4, sd_rt_0.6, sd_rt_1)),
      index == "longstring" ~ list(c(longstring_6, longstring_7, longstring_8)),
      index == "mode" ~ list(c(mode_5, mode_6)),
      index == "anto" ~ list(c(anto_0))
    ),
    cutoff_labels = case_when(
      index == "sd_within" ~ list(c("0.75", "1.0", "1.25")),
      index == "avg_rt" ~ list(c("1.0", "1.5", "2.0")),
      index == "sd_rt" ~ list(c("0.4", "0.6", "1.0")),
      index == "longstring" ~ list(c("6", "7", "8")),
      index == "mode" ~ list(c("5", "6")),
      index == "anto" ~ list(c("0"))
    )
  ) |>
  unnest_longer(c(cutoff_values, cutoff_labels)) |>
  mutate(
    proportion_flagged = round(as.numeric(cutoff_values) * 100, 2),
    cutoff = cutoff_labels
  ) |>
  select(Index = index, Cutoff = cutoff, `Proportion flagged (%)` = proportion_flagged)


# create flextable
ft <- clean_table_long |>
  flextable() |>
  flextable::theme_vanilla() |>
  flextable::autofit() |>
  flextable::align(align = "center", part = "all")

# ft
  
```




## Large grid plot with all indices

Our goal is to create one large overview plot with all indices. 

We first create a plot for all integer/proportion indices: 
```{r}
integer_plot <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  dplyr::select(anto_violations,
         # syno_violations,
         longstring_count,
         mode_count) |>
  rename(
    # "Synonym" = "syno_violations",
    "Antonym" = "anto_violations",
    "Longstring" = "longstring_count",
    "Items at Mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value)) +
  geom_bar(fill = fill_color) +
  ggh4x::facet_wrap2(. ~ index, scales = "free_y", axes = "all") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(breaks = 0:10) +
  theme_bs() +
  labs(x = "", y = "")
```

Alternatively, convert the plot to percentages: 
```{r}
integer_plot_pct <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  dplyr::select(anto_violations,
         # syno_violations,
         longstring_count,
         mode_count) |>
  rename(
    # "Synonym" = "syno_violations",
    "Antonym" = "anto_violations",
    "Longstring" = "longstring_count",
    "Items at Mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value, y = after_stat(prop))) +  # for percentage
  geom_bar(fill = fill_color) +
  ggh4x::facet_wrap2(. ~ index, scales = "free_y", axes = "all") +
  scale_y_continuous(expand = c(0, 0), labels = scales::percent_format()) +
  scale_x_continuous(
    breaks = 0:11,
    expand = c(0, 0),
    limits = c(-.6, 11.1)
  ) +
  theme_bs() +
  labs(x = "", y = "Percentage")
integer_plot_pct
```


Then create a plot for all continuous indices: 
```{r}
cont_plot <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  filter(sd_response_time < 10) |>
  dplyr::select(assessment_sd,
         mahalanobis_dist,
         robustpca_dist,
         average_response_time,
         sd_response_time,
  ) |>
  rename(
    "Assessment SD" = "assessment_sd",
    "Mahalanobis" = "mahalanobis_dist",
    "Robust PCA" = "robustpca_dist",
    "Average RT" = "average_response_time",
    "SD RT" = "sd_response_time"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value)) +
  geom_density(fill = fill_color,
               color = fill_color,
               # use finer bandwidth
               adjust = 1 / 4) +
  ggh4x::facet_wrap2(. ~ index, scales = "free") +
  scale_y_continuous(expand = c(0, 0), labels = scales::label_percent()) +
  theme_bs() +
  labs(x = "", y = "")

cont_plot
```

Combine the plots: 
```{r}
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 10
combined_plot <- cowplot::plot_grid(integer_plot_pct, cont_plot, nrow = 2)

combined_plot

ggsave("indices_overview.pdf", 
       plot = combined_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```

## Visualizing the Multiverse

In `01_calculate_indices.qmd`, we conducted a multiverse-style analysis of carelessness indices to understand the overlap between them, and their conservativeness. 

We now visualize the results of these analyses below. First, we show a table of all results across the multiverse:

```{r}
#| label: multiverse-flag-table
# then plot as large table
flag_multiverse <- readRDS(here::here("output", "flag_multiverse.RDS"))
flag_multiverse |>
  gt::gt()
```

### Multiverse Correlations

To understand the impact of different cutoffs for careless respondings, we can investigate how certain properties of the data or model results change before and after the exclusion of responses marked as careless. Here, inspired by Jaso et al. (2021), we do so by investigating how correlations between two items change. We pick "nervous" and "overwhelmed", as we expect these to correlate highly in non-careless responses.

Here is a visual summary of the results across different specifications in the form of a specification curve, first for the single-hurdle approach:
```{r}
df_cors_spec <- readRDS(here::here("output", "df_cors.RDS"))
# Combine plots
correlation_plot_single <- df_cors_spec |> 
    dplyr::arrange(correlation_1plus) |> 
    dplyr::mutate(iteration = dplyr::row_number()) |>
    ggplot(aes(x = iteration, y = correlation_1plus)) + 
    geom_point(size = 0.8) +
    theme_bs() +
    labs(x = "", y = "Correlation", subtitle = "Single-Hurdle Approach")
specification_plot <- plot_specification(df_cors_spec,
                                         type = "cor",
                                         hurdle = "single")

mv_plot_cors_single <- plot_grid(correlation_plot_single, specification_plot, 
          ncol = 1, rel_heights = c(1, 2), axis = "b",
          align = "h")

mv_plot_cors_single
ggsave("mv_plot_cors_single.pdf", mv_plot_cors_single, device = "pdf", path = here::here("figures"),
       height = 9, width = 10)
```

Then for the multiple hurdle approach with two "hurdles":

```{r}
# Combine plots
correlation_plot_double <- df_cors_spec |> 
    dplyr::arrange(correlation_2plus) |> 
    dplyr::mutate(iteration = dplyr::row_number()) |>
    ggplot(aes(x = iteration, y = correlation_2plus)) + 
    geom_point(size = 0.8) +
    theme_bs() +
    labs(x = "", y = "Correlation", subtitle = "Duoble-Hurdle Approach")
specification_plot <- plot_specification(df_cors_spec,
                                         type = "cor",
                                         hurdle = "double")

mv_plot_cors_double <- plot_grid(
  correlation_plot_double,
  specification_plot,
  ncol = 1,
  rel_heights = c(1, 2),
  axis = "b",
  align = "h"
)

mv_plot_cors_double
ggsave("mv_plot_cors_double.pdf", mv_plot_cors_double, device = "pdf", path = here::here("figures"),
       height = 9, width = 10)

```


### Multiverse Similarity
Instead of checking the correlation between affect items, we can instead check the overlap between carelessness flags based on the indices and the model-based indices across the multiverse. To do so, we use similarity metrics.

Visualize the results for both models and the single and double hurdle approach: 
```{r}
#| label: multiverse-similarity-plots
df_jaccard_spec <- readRDS(here::here("output", "df_jaccard_spec.RDS"))
hurdles <- c("single", "double")
models <- c("lpa", "irt")
type <- "similarity"

# plots for similarities
for(model in models) {
  for(hurdle in hurdles) {
    sim_plot <- plot_similarity(df_jaccard_spec, model, hurdle = hurdle)
    spec_plot <- plot_specification(df_jaccard_spec, type = "similarity", model = model, hurdle = hurdle)
    
    mv_plot <- plot_grid(
      sim_plot,
      spec_plot,
      ncol = 1,
      rel_heights = c(1, 2),
      align = "h",
      axis = "b"
    )
    
    ggsave(
      paste0("mv_plot_similarity_", model, "_", hurdle, ".pdf"),
      mv_plot,
      device = "pdf",
      path = here::here("figures"),
      height = 10,
      width = 10
    )
  }
}
```

# Similarity Indices and Models

We attach the model results to the indices. We classify everyone with an LPA profile 1 or 2, and a mixture IRT class 1 as attentive. 
```{r}
#| label: attach-model
df_indices_models <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |> 
  left_join(flag_df, by = c("external_id", "counter")) |> 
    mutate(across(where(is.logical), ~ as.integer(.))) |> 
    mutate(flag_lpa = ifelse(LPA_profile != 2, 1, 0),
           flag_irt = ifelse(mixtureIRT == 1, 0, 1)) |> 
   select(contains("flag")) |> 
  # recode to obtain single hurdle and multiple hurdle approach
  mutate(
    single_hurdle = if_else(flag_sum == 0, 0, 1),
    double_hurdle = if_else(flag_sum < 2, 0, 1)
  ) |> 
  # then remove raw sum
  select(!flag_sum)
  
```


## Large grid plot with indicators and model results


### LPA and Mixture IRT
Create distribution plot for the LPA and mixture IRT: 

```{r}
#| label: model-distributions
lpa_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  count(LPA_profile) |> 
  mutate(percent = n / sum(n))

# plot LPA results
lpa_dist_plot <- lpa_prop_df |> 
  ggplot(aes(x = as.factor(LPA_profile), y = percent, fill = as.factor(LPA_profile))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_viridis_d() +
  scale_y_continuous(limits = c(0, .45), expand = c(0, 0), labels = scales::percent_format()) +
  theme_bs() +
  labs(x = "Profile Membership", 
       y = "",
       title = "Latent Profile")

lpa_dist_plot  

ggsave("lpa_descriptive_plot.pdf", 
       plot = lpa_dist_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```

Plot mixture IRT class membership overall:
```{r}
irt_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  count(mixtureIRT) |> 
  mutate(percent = n / sum(n)) |> 
  filter(!is.na(mixtureIRT))

# plot irt results
irt_dist_plot <- irt_prop_df |>
  ggplot(aes(
    x = as.factor(mixtureIRT),
    y = percent,
    fill = as.factor(mixtureIRT)
  )) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_viridis_d() +
  scale_y_continuous(
    limits = c(0, 1.05),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  theme_bs() +
  labs(x = "Mixture IRT Class", y = "Percentage of Participants")

irt_dist_plot  

ggsave("irt_descriptive_plot.pdf", 
       plot = irt_dist_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```

Plot mixture IRT class membership by calculating how often each individual was classified as being in the inattentive state:

```{r}
irt_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  filter(!is.na(mixtureIRT)) |> 
  group_by(external_id) |> 
  summarise(n_careless = sum(mixtureIRT == 2, na.rm = TRUE)) |> 
  ungroup()

# summarize how many participants had X number of careless time points
irt_summary_df <- irt_prop_df |> 
  count(n_careless) |> 
  mutate(percent = n / sum(n))

# plot
irt_dist_plot_timepoints <- irt_summary_df |> 
  ggplot(aes(x = n_careless, y = percent)) +
  geom_bar(stat = "identity", show.legend = FALSE, fill = fill_color) +
  scale_y_continuous(
    limits = c(0, .25),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  scale_x_continuous(
    breaks = scales::pretty_breaks(),
    expand = c(0, 0)
  ) +
  theme_bs() +
  labs(
    x = "Number of Careless Time Points",
    # y = "Percentage of Participants"
  )

irt_dist_plot_timepoints

```

Alternatively, we can bin the number of careless time points:
```{r}
# bin careless counts
irt_binned_df <- irt_prop_df |> 
  mutate(
    careless_bin = cut(
      n_careless,
      breaks = c(-Inf, 0, 5, 10, 20, 50, Inf),
      labels = c("0", "1–5", "6–10", "11–20", "21–50", "51+"),
      right = TRUE
    )
  )

# summarize number of participants in each bin
irt_summary_df <- irt_binned_df |> 
  count(careless_bin) |> 
  mutate(percent = n / sum(n))

# plot
irt_dist_plot_binned <- irt_summary_df |> 
  ggplot(aes(x = careless_bin, y = percent)) +
  geom_bar(stat = "identity", show.legend = FALSE, fill = fill_color) +
  scale_y_continuous(
    limits = c(0, .45),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  # scale_fill_viridis_d() +
  theme_bs() +
  labs(
    x = "N° of Careless Time Points",
    y = "",
    title = "Mixture IRT"
  )
  # theme(
  #   axis.text.x = element_text(size = 15)
  # )

irt_dist_plot_binned
```


### Combined with indices plots

Now combine these plots with all individual indices plots:
```{r giga-plot}
#| message: false
#| warning: false
#| fig-height: 16
#| fig-width: 11
# create individual plots for each index
df_integer_long <- df_indices |>
  select(!c(external_id, counter, k_values)) |>
  select(
    anto_violations,
    longstring_count,
    mode_count
  ) |>
  rename(
    "Antonym violation" = "anto_violations",
    "Long string count" = "longstring_count",
    "Items that fall at the mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  # recode antonym violation 
  mutate(
    value_label = case_when(
      index == "Antonym violation" & value == 0 ~ "no",
      index == "Antonym violation" & value == 1 ~ "yes",
      TRUE ~ as.character(value)
    ),
    # create labels for display
    value_numeric = value,
    value_display = if_else(index == "Antonym violation", value_label, as.character(value))
  )

# create list of individual bar plots
integer_plot_list <- df_integer_long |>
  group_split(index) |>
  map(~ {
    index_label <- unique(.x$index)
    
    
    p <- ggplot(.x, aes(x = value_numeric, y = after_stat(prop))) +
      geom_bar(fill = fill_color) +
      scale_y_continuous(expand = c(0, 0), labels = scales::percent_format()) +
      theme_bs() +
      labs(x = "", y = "") +
      ggtitle(index_label)
    
    # customize x-axis for the antonym violation (binary) plot
    if (index_label == "Antonym violation") {
      p <- p + scale_x_continuous(
        breaks = c(0, 1),
        labels = c("no", "yes"), 
        limits = c(-0.5, 1.5),
        expand = c(0, 0)
      )
    } else {
      p <- p + scale_x_continuous(
        breaks = 0:11,
        limits = c(-0.6, 9.1),
        expand = c(0, 0)
      )
    }
    p
  })

# create list of individual density plots
df_cont_long <- df_indices |>
  select(!c(external_id, counter, k_values)) |>
  filter(sd_response_time < 10) |>
  select(
    assessment_sd,
    mahalanobis_dist,
    robustpca_dist,
    average_response_time,
    sd_response_time
  ) |>
  rename(
    "Within-assessment response SD" = "assessment_sd",
    "Mahalanobis distance" = "mahalanobis_dist",
    "Robust PCA distance" = "robustpca_dist",
    "Average time-per-item" = "average_response_time",
    "SD time-per-item" = "sd_response_time"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value))


cont_plot_list <- df_cont_long |>
  group_split(index) |>
  map(~ {
    # scaled densities
    ggplot(.x, aes(x = value, ..scaled..)) +
      geom_density(fill = fill_color, color = fill_color, adjust = 1 / 4) +
      scale_y_continuous(expand = c(0, 0)) +
      theme_bs() +
      labs(x = "", y = "") +
      ggtitle(unique(.x$index))
  })

# combine into grid
plot_grid_list <- c(integer_plot_list, cont_plot_list, list(lpa_dist_plot, irt_dist_plot_binned))

combined_plot_all <- cowplot::plot_grid(
  plotlist = plot_grid_list,
  ncol = 2,  
  align = "hv"
)

combined_plot_all

ggsave("indices_models_overview.pdf", 
       plot = combined_plot_all, 
       path = here::here("figures"),
       height = 16, 
       width = 11)
```


Alternatively, we can add the same plot without the two models:

```{r}
#| label: distribution-plot-indices-only
#| warning: false
#| message: false
plot_grid_list <- c(integer_plot_list, cont_plot_list)

# reorder based on order in methods section
plot_grid_list <- plot_grid_list[c(3, 2, 8, 5, 6, 1, 4, 7)]

combined_plot_indices <- cowplot::plot_grid(
  plotlist = plot_grid_list,
  ncol = 2,  
  align = "hv"
)

ggsave("indices_overview_twocol.pdf", 
       plot = combined_plot_indices, 
       path = here::here("figures"),
       height = 14, 
       width = 11)
```



## Additional plot with number of careless observations


In one plot, we show the number of careless observations with a single and double-hurdle approach and the two models. 

```{r}
#| label: careless-response-number-figure

# create method labels
method_labels <- c(
  "flag_lpa" = "Latent Profile Analysis",
  "flag_irt" = "Mixture IRT", 
  "single_hurdle" = "Single Hurdle",
  "double_hurdle" = "Double Hurdle"
)

model_hurdle_counts <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |> 
  left_join(flag_df, by = c("external_id", "counter")) |> 
    mutate(across(where(is.logical), ~ as.integer(.))) |> 
    mutate(flag_lpa = ifelse(LPA_profile != 2, 1, 0),
           flag_irt = ifelse(mixtureIRT == 1, 0, 1)) |> 
  # recode to obtain single hurdle and multiple hurdle approach
  mutate(
    single_hurdle = if_else(flag_sum == 0, 0, 1),
    double_hurdle = if_else(flag_sum < 2, 0, 1)
  ) |> 
  select(external_id, flag_lpa, flag_irt, single_hurdle, double_hurdle) |> group_by(external_id) |> 
  summarize(across(everything(), sum)) |> 
  select(!external_id) |> 
    pivot_longer(everything(), names_to = "method", values_to = "count") |>
  filter(!is.na(count)) |> 
  mutate(method = factor(method, levels = names(method_labels)))



# create bins with same breaks for all methods
binned_df <- model_hurdle_counts |>
  mutate(
    careless_bin = cut(
      count,
      breaks = c(-Inf, 0, 10, 25, 50, 100, 200, Inf),
      labels = c("0", "1–10", "11–25", "26–50", "51–100", "101–200", "201+"),
      right = TRUE
    )
  )

# summarize proportions by method and bin
summary_df <- binned_df |>
  group_by(method, careless_bin) |>
  summarise(n = n(), .groups = "drop") |>
  group_by(method) |>
  mutate(percent = n / sum(n)) |>
  ungroup()



# plot
careless_dist_plot <- summary_df |>
  ggplot(aes(x = careless_bin, y = percent)) +
  geom_bar(stat = "identity",
           show.legend = FALSE,
           fill = fill_color) +
  ggh4x::facet_wrap2( ~ method, 
                      labeller = labeller(method = method_labels),
                      axes = "all")  +
  scale_y_continuous(
    limits = c(0, 0.75),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  theme_bs() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 10, face = "bold")
  ) +
  labs(x = "Number of Careless Responses", y = "Proportion of Participants")

careless_dist_plot


ggsave("careless_count_plot.pdf", 
       plot = careless_dist_plot, 
       path = here::here("figures"),
       height = 9, 
       width = 11)
```


We can create the same plot also including the sensitivity cutoffs: 

```{r}
# create method labels
method_labels <- c(
  "flag_lpa" = "Latent Profile Analysis",
  "flag_irt" = "Mixture IRT", 
  "single_hurdle_default" = "Single Hurdle (Default)",
  "double_hurdle_default" = "Double Hurdle (Default)",
  "single_hurdle_sensitivity" = "Single Hurdle (Sensitivity)",
  "double_hurdle_sensitivity" = "Double Hurdle (Sensitivity)"
)

model_hurdle_counts <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |> 
  left_join(flag_df, by = c("external_id", "counter")) |> 
  left_join(lenient_flag_df, by = c("external_id", "counter"), suffix = c("_default", "_sensitivity")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  mutate(flag_lpa = ifelse(LPA_profile != 2, 1, 0),
         flag_irt = ifelse(mixtureIRT == 1, 0, 1)) |> 
  # recode to obtain single hurdle and multiple hurdle approach for both specifications
  mutate(
    single_hurdle_default = if_else(flag_sum_default == 0, 0, 1),
    double_hurdle_default = if_else(flag_sum_default < 2, 0, 1),
    single_hurdle_sensitivity = if_else(flag_sum_sensitivity == 0, 0, 1),
    double_hurdle_sensitivity = if_else(flag_sum_sensitivity < 2, 0, 1)
  ) |> 
  select(external_id, flag_lpa, flag_irt, single_hurdle_default, double_hurdle_default, 
         single_hurdle_sensitivity, double_hurdle_sensitivity) |> 
  group_by(external_id) |> 
  summarize(across(everything(), sum)) |> 
  select(!external_id) |> 
  pivot_longer(everything(), names_to = "method", values_to = "count") |>
  filter(!is.na(count)) |> 
  mutate(method = factor(method, levels = names(method_labels)))

# create bins with same breaks for all methods
binned_df <- model_hurdle_counts |>
  mutate(
    careless_bin = cut(
      count,
      breaks = c(-Inf, 0, 10, 25, 50, 100, 200, Inf),
      labels = c("0", "1–10", "11–25", "26–50", "51–100", "101–200", "201+"),
      right = TRUE
    )
  )

# summarize proportions by method and bin
summary_df <- binned_df |>
  group_by(method, careless_bin) |>
  summarise(n = n(), .groups = "drop") |>
  group_by(method) |>
  mutate(percent = n / sum(n)) |>
  ungroup()

# plot
careless_dist_plot_sens <- summary_df |>
  ggplot(aes(x = careless_bin, y = percent)) +
  geom_bar(stat = "identity",
           show.legend = FALSE,
           fill = fill_color) +
  ggh4x::facet_wrap2( ~ method, 
                      labeller = labeller(method = method_labels),
                      axes = "all",
                      nrow = 3)  +
  scale_y_continuous(
    limits = c(0, 0.75),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  theme_bs() +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    strip.text = element_text(size = 10, face = "bold")
  ) +
  labs(x = "Number of Careless Responses", y = "Proportion of Participants")

careless_dist_plot_sens

ggsave("careless_count_plot_sensitivity.pdf", 
       plot = careless_dist_plot_sens, 
       path = here::here("figures"),
       height = 13.5, 
       width = 11)  
```



## Jaccard Similarity of Indices and Model Results

We can visualize the classification of careless responding based on indices and and model results with a Jaccard similarity heatmap. 

### Main Specification

```{r jaccard-similarity}
jaccard_matrix <- vegan::vegdist(
  t(df_indices_models),
  na.rm = TRUE,
  method = "jaccard",
  binary = TRUE
)
jaccard_matrix <- as.matrix(jaccard_matrix)

# convert dissimilarity to similarity
jaccard_sim_matrix <- 1-jaccard_matrix

# self-similarity
diag(jaccard_sim_matrix) <- 1

column_order <- c("Longstring", "Mode", "SD within", "Antonym", "Avg. RT", "SD RT", "Single", "Double", "LPA", "IRT")

similarity_plot <- jaccard_sim_matrix |>
  as.data.frame() |>
  rownames_to_column(var = "Var1") |>
  pivot_longer(-Var1, names_to = "Var2", values_to = "Similarity") |>
  mutate(
    Var1 = case_when(
      Var1 == "flag_sd_within" ~ "SD within",
      Var1 == "flag_average_response_time" ~ "Avg. RT",
      Var1 == "flag_sd_response_time" ~ "SD RT",
      Var1 == "flag_longstring" ~ "Longstring",
      Var1 == "flag_mode" ~ "Mode",
      Var1 == "flag_anto" ~ "Antonym",
      Var1 == "flag_lpa" ~ "LPA",
      Var1 == "flag_irt" ~ "IRT",
      Var1 == "single_hurdle" ~ "Single",
      Var1 == "double_hurdle" ~ "Double",
      TRUE ~ Var1
    ),
    Var2 = case_when(
      Var2 == "flag_sd_within" ~ "SD within",
      Var2 == "flag_average_response_time" ~ "Avg. RT",
      Var2 == "flag_sd_response_time" ~ "SD RT",
      Var2 == "flag_longstring" ~ "Longstring",
      Var2 == "flag_mode" ~ "Mode",
      Var2 == "flag_anto" ~ "Antonym",
      Var2 == "flag_lpa" ~ "LPA",
      Var2 == "flag_irt" ~ "IRT",
      Var2 == "single_hurdle" ~ "Single",
      Var2 == "double_hurdle" ~ "Double",
      TRUE ~ Var2
    )) |> 
  mutate(
    Var1 = factor(Var1, levels = column_order),
    Var2 = factor(Var2, levels = rev(column_order)),
    text_color = if_else(Var1 == Var2, "white", "black")
  ) |>
  ggplot(aes(x = Var1, y = Var2, fill = Similarity)) +
  geom_tile(color = "white") +
  scale_fill_gradient(
    low = "white",
    high = fill_color,
    limit = c(0, 1),
    space = "Lab",
    name = "Jaccard\nSimilarity"
  ) +
  theme_bs() + 
  theme(
    axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    legend.justification = c(1, 0),
    legend.position = "none"
  ) +
  coord_fixed() +
  geom_text(aes(label = round(Similarity, 2), color = text_color), size = 3.8) +
  scale_color_identity()

similarity_plot

ggsave("similarity_plot.pdf", similarity_plot, path = here::here("figures"),
       width = 7, height = 5)

```

We create the same plot with a row indicating the mean similarity for each method:
```{r similarity-plot-mean}
# Calculate mean similarities (excluding diagonal)
mean_similarities <- sapply(1:ncol(jaccard_sim_matrix), function(i) {
  col_vals <- jaccard_sim_matrix[, i]
  mean(col_vals[-i])  # exclude diagonal element
})
names(mean_similarities) <- colnames(jaccard_sim_matrix)

# main similarity data
similarity_data <- jaccard_sim_matrix |>
  as.data.frame() |>
  rownames_to_column(var = "Var1") |>
  pivot_longer(-Var1, names_to = "Var2", values_to = "Similarity") |>
  mutate(
    Var1 = case_when(
      Var1 == "flag_sd_within" ~ "SD within",
      Var1 == "flag_average_response_time" ~ "Avg. RT",
      Var1 == "flag_sd_response_time" ~ "SD RT",
      Var1 == "flag_longstring" ~ "Longstring",
      Var1 == "flag_mode" ~ "Mode",
      Var1 == "flag_anto" ~ "Antonym",
      Var1 == "flag_lpa" ~ "LPA",
      Var1 == "flag_irt" ~ "IRT",
      Var1 == "single_hurdle" ~ "Single",
      Var1 == "double_hurdle" ~ "Double",
      TRUE ~ Var1
    ),
    Var2 = case_when(
      Var2 == "flag_sd_within" ~ "SD within",
      Var2 == "flag_average_response_time" ~ "Avg. RT",
      Var2 == "flag_sd_response_time" ~ "SD RT",
      Var2 == "flag_longstring" ~ "Longstring",
      Var2 == "flag_mode" ~ "Mode",
      Var2 == "flag_anto" ~ "Antonym",
      Var2 == "flag_lpa" ~ "LPA",
      Var2 == "flag_irt" ~ "IRT",
      Var2 == "single_hurdle" ~ "Single",
      Var2 == "double_hurdle" ~ "Double",
      TRUE ~ Var2
    ),
    row_type = "main"
  )

# mean row data
mean_data <- data.frame(
  Var1 = "Mean",
  Var2 = names(mean_similarities),
  Similarity = as.numeric(mean_similarities),
  row_type = "mean"
) |>
  mutate(
    Var2 = case_when(
      Var2 == "flag_sd_within" ~ "SD within",
      Var2 == "flag_average_response_time" ~ "Avg. RT",
      Var2 == "flag_sd_response_time" ~ "SD RT",
      Var2 == "flag_longstring" ~ "Longstring",
      Var2 == "flag_mode" ~ "Mode",
      Var2 == "flag_anto" ~ "Antonym",
      Var2 == "flag_lpa" ~ "LPA",
      Var2 == "flag_irt" ~ "IRT",
      Var2 == "single_hurdle" ~ "Single",
      Var2 == "double_hurdle" ~ "Double",
      TRUE ~ Var2
    )
  )

# combine data
combined_data <- rbind(similarity_data, mean_data) |>
  mutate(
    text_color = case_when(
      row_type == "mean" ~ "black",
      Var1 == Var2 ~ fill_color,
      TRUE ~ "black"
    ),
    Var1 = factor(Var1, levels = c("Mean", rev(column_order))),
    Var2 = factor(Var2, levels = column_order)
  )


similarity_plot_mean <- combined_data |>
  ggplot(aes(x = Var2, y = Var1, fill = Similarity)) +
  geom_tile(color = "white", size = ifelse(combined_data$row_type == "mean", 2, 0.5)) +
  # Add a thicker separator line above the mean row
  geom_hline(yintercept = 1.5, color = "#6d6d6e", linewidth = .5, linetype = 2) +
  scale_fill_gradient(
    low = "white",
    high = fill_color,  
    limit = c(0, 1),
    space = "Lab",
    name = "Jaccard\nSimilarity"
  ) +
  theme_bs() + 
  theme(
    axis.text.x = element_text(angle = 45, vjust = 0, hjust = 0),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    legend.justification = c(1, 0),
    legend.position = "none",
    axis.text.x.top = element_text(angle = 45, vjust = 0, hjust = 0),
    axis.text.x.bottom = element_blank(),
    plot.margin = margin(t = 5,r = 1,b = 5,l = 1)
  ) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  geom_text(aes(label = round(Similarity, 2), color = text_color), size = 3.8) +
  scale_color_identity()+
  labs(title = "Default")

similarity_plot_mean

ggsave("similarity_plot_mean.pdf", similarity_plot_mean, path = here::here("figures"),
       width = 7, height = 5)
```


### Lenient/Sensitivity Specification

Instead of using the main specification, we can use the most lenient one here:
```{r}
df_indices_models_lenient <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |> 
  left_join(lenient_flag_df, by = c("external_id", "counter")) |> 
    mutate(across(where(is.logical), ~ as.integer(.))) |> 
    mutate(flag_lpa = ifelse(LPA_profile != 2, 1, 0),
           flag_irt = ifelse(mixtureIRT == 1, 0, 1)) |> 
   select(contains("flag")) |> 
  # recode to obtain single hurdle and multiple hurdle approach
  mutate(
    single_hurdle = if_else(flag_sum == 0, 0, 1),
    double_hurdle = if_else(flag_sum < 2, 0, 1)
  ) |> 
  # then remove raw sum
  select(!flag_sum)
```

We then re-create the Jaccard similarity plot: 

```{r}
jaccard_matrix <- vegan::vegdist(
  t(df_indices_models_lenient),
  na.rm = TRUE,
  method = "jaccard",
  binary = TRUE
)
jaccard_matrix <- as.matrix(jaccard_matrix)

# convert dissimilarity to similarity
jaccard_sim_matrix <- 1-jaccard_matrix

# self-similarity
diag(jaccard_sim_matrix) <- 1

column_order <- c("Longstring", "Mode", "SD within", "Antonym", "Avg. RT", "SD RT", "Single", "Double", "LPA", "IRT")

mean_similarities <- sapply(1:ncol(jaccard_sim_matrix), function(i) {
  col_vals <- jaccard_sim_matrix[, i]
  mean(col_vals[-i])  # exclude diagonal element
})
names(mean_similarities) <- colnames(jaccard_sim_matrix)

# main similarity data
similarity_data <- jaccard_sim_matrix |>
  as.data.frame() |>
  rownames_to_column(var = "Var1") |>
  pivot_longer(-Var1, names_to = "Var2", values_to = "Similarity") |>
  mutate(
    Var1 = case_when(
      Var1 == "flag_sd_within" ~ "SD within",
      Var1 == "flag_average_response_time" ~ "Avg. RT",
      Var1 == "flag_sd_response_time" ~ "SD RT",
      Var1 == "flag_longstring" ~ "Longstring",
      Var1 == "flag_mode" ~ "Mode",
      Var1 == "flag_anto" ~ "Antonym",
      Var1 == "flag_lpa" ~ "LPA",
      Var1 == "flag_irt" ~ "IRT",
      Var1 == "single_hurdle" ~ "Single",
      Var1 == "double_hurdle" ~ "Double",
      TRUE ~ Var1
    ),
    Var2 = case_when(
      Var2 == "flag_sd_within" ~ "SD within",
      Var2 == "flag_average_response_time" ~ "Avg. RT",
      Var2 == "flag_sd_response_time" ~ "SD RT",
      Var2 == "flag_longstring" ~ "Longstring",
      Var2 == "flag_mode" ~ "Mode",
      Var2 == "flag_anto" ~ "Antonym",
      Var2 == "flag_lpa" ~ "LPA",
      Var2 == "flag_irt" ~ "IRT",
      Var2 == "single_hurdle" ~ "Single",
      Var2 == "double_hurdle" ~ "Double",
      TRUE ~ Var2
    ),
    row_type = "main"
  )

# mean row data
mean_data <- data.frame(
  Var1 = "Mean",
  Var2 = names(mean_similarities),
  Similarity = as.numeric(mean_similarities),
  row_type = "mean"
) |>
  mutate(
    Var2 = case_when(
      Var2 == "flag_sd_within" ~ "SD within",
      Var2 == "flag_average_response_time" ~ "Avg. RT",
      Var2 == "flag_sd_response_time" ~ "SD RT",
      Var2 == "flag_longstring" ~ "Longstring",
      Var2 == "flag_mode" ~ "Mode",
      Var2 == "flag_anto" ~ "Antonym",
      Var2 == "flag_lpa" ~ "LPA",
      Var2 == "flag_irt" ~ "IRT",
      Var2 == "single_hurdle" ~ "Single",
      Var2 == "double_hurdle" ~ "Double",
      TRUE ~ Var2
    )
  )

# combine data
combined_data <- rbind(similarity_data, mean_data) |>
  mutate(
    text_color = case_when(
      row_type == "mean" ~ "black",
      Var1 == Var2 ~ fill_color,
      TRUE ~ "black"
    ),
    Var1 = factor(Var1, levels = c("Mean", rev(column_order))),
    Var2 = factor(Var2, levels = column_order)
  )


similarity_plot_mean_lenient <- combined_data |>
  ggplot(aes(x = Var2, y = Var1, fill = Similarity)) +
  geom_tile(color = "white", size = ifelse(combined_data$row_type == "mean", 2, 0.5)) +
  # Add a thicker separator line above the mean row
  geom_hline(yintercept = 1.5, color = "#6d6d6e", linewidth = .5, linetype = 2) +
  scale_fill_gradient(
    low = "white",
    high = fill_color,  
    limit = c(0, 1),
    space = "Lab",
    name = "Jaccard\nSimilarity"
  ) +
  theme_bs() + 
  theme(
    axis.text.x = element_text(angle = 45, vjust = 0, hjust = 0),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.border = element_blank(),
    legend.justification = c(1, 0),
    legend.position = "none",
    axis.text.x.top = element_text(angle = 45, vjust = 0, hjust = 0),
    axis.text.x.bottom = element_blank(),
    plot.margin = margin(t = 5,r = 1,b = 5,l = 1)
  ) +
  scale_x_discrete(position = "top") +
  coord_fixed() +
  geom_text(aes(label = round(Similarity, 2), color = text_color), size = 3.8) +
  scale_color_identity()+
  labs(title = "Sensitivity")

similarity_plot_mean_lenient

ggsave(
  "similarity_plot_mean_lenient.pdf",
  similarity_plot_mean_lenient,
  path = here::here("figures"),
  width = 7,
  height = 5
)
```

### Combine Specification Plots

We combine both Jaccard similarity mean plots in one plot: 

```{r}
#| fig-width: 11
#| fig-height: 6
#| label: jaccard-plots-combined

jaccard_plot_combined <- similarity_plot_mean + plot_spacer() +  similarity_plot_mean_lenient + plot_layout(ncol = 3, widths = c(1, 0.05, 1))

ggsave(
  "jaccard_plot_combined.pdf",
  jaccard_plot_combined,
  path = here::here("figures"),
  width = 11,
  height = 6
)

jaccard_plot_combined
```


# Session Info

```{r session-info}
pander::pander(sessionInfo())

```

