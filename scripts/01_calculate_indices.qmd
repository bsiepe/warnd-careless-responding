---
title: "Careless Responding"
subtitle: "Calculating Indices"
author: 
 - name: Bj√∂rn S. Siepe
   orcid: 0000-0002-9558-4648
   affiliations: University of Marburg
 - name: Add name(s) of person(s) responsible for respective file
   orcid: 0000-0002-9558-4648
   affiliations: to be added
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    number-sections: true
    theme: cosmo
    code-fold: true
    code-tools: true
    code-summary: "Show the code"
    fig-width: 7
    fig-height: 4.5
    fig-align: "center"
    embed-resources: true
execute:
  message: false
  warning: false
  eval: true # run code?
---

# Background
In this file, we will compute all indices of careless responding. We aim for the following structure: 
`external_id`, `counter`, `index`. There should be no implicit missingness. 

TODOS:

    - Check the warnings for mahalanobis
    
    - We should maybe return 0 for the within-assessment-SD instead of NA when there is no variability at all. 
     
    - use `ggbreak` to display large integer values in synonym and antonym violation.


We first load all relevant packages: 
```{r packages}
if(!require(pacman)) install.packages("pacman")
pacman::p_load("dplyr", "tidyr", "here", "ggplot2", "rrcov", "Hmisc", "sysfonts", "showtext", 
               "ggh4x", "cowplot", "gtsummary", "gt")  

source(here("scripts", "00_functions.R"))
  
set.seed(35032)  
```


We load the data and remove all non-EMA prompts. Insert your dataset in the subfolder `/data/` and load it here. 
```{r read-data}
data <- read.csv(here::here("data", "WARND_stage2_c1234_trainingset_before_30min_v2024_07_16.csv"))

data <- data |> 
  filter(!is.na(counter))
```

Relevant EMA items and their reaction times: 
```{r ema-itemss}
ema_items <-  c("sad_d", "stressed_d", "overwhelm_d", "nervous_d", "ruminate_d", "irritable_d", "cheerful_d", "motivated_d", "relaxed_d")
rt_ema_items <- paste0("rt_", ema_items)

```


# Data Preparation

We first subset the data for testing the functions on a smaller dataframe of 30 individuals:

```{r subset-data, eval = FALSE}
# select 30 individuals at random
ids_to_subset <- data |> 
  distinct(external_id) |> 
  slice_sample(n = 30) |> 
  pull(external_id)


subset_data <- data |> 
  filter(external_id %in% ids_to_subset)

saveRDS(subset_data, file = here::here("data", "indices_experiment_data.RDS"))

```

```{r, include = FALSE}
subset_data <- readRDS(here::here("data", "indices_experiment_data.RDS"))
```



# Analysis

Currently, this still depends on `sd_within_assessment` being the first, to have no implicit missingness when using `left_join()` later below.
```{r}
# Define the functions and their parameters
index_functions <- list(
    sd_within_assessment = list(
    func = calc_within_assessment_sd,
    args = list(
      items = ema_items,
      id_col = "external_id"
    )
  ),
  mahalanobis = list(
    func = calc_indicator_mahalanobis,
    args = list(items = ema_items)
  ),
  robust_pca = list(
    func = calc_indicator_rob_PCA_orthogonal_distance,
    args = list(items = ema_items)
  ),
  psychometric_syntonym = list(
    func = calc_psychometric_synonym_violations,
    args = list(
      items = ema_items,
      cor_threshold = 0.45,
      synonym_difference_threshold = 5
    )
  ),
  psychometric_antonym = list(
    func = calc_psychometric_antonym_violations,
    args = list(
      items = ema_items,
      cor_threshold = 0.45,
      antonym_maxvalue_threshold = 5
    )
  ),
  sd_response_times = list(
    func = calc_sd_response_times,
    args = list(items = rt_ema_items)
  ),

  items_at_mode = list(
    func = calc_mode_percentage,
    args = list(
      items = ema_items,
      id_col = "external_id"
    )
  ),
  longstring = list(
    func = calc_longstring_proportions, 
    args = list(
      items = ema_items, 
      rt_items = rt_ema_items
    )
  )
)


```


Calculate them all on the subset:

```{r calc-indices, message=FALSE}
# calculate all indices
indices <- index_functions |>
  purrr::map(
    .f = function(x) {
      do.call(x$func, c(list(data = subset_data), x$args))
    }
  )

# combine indices
df_indices <- indices |>
  purrr::reduce(
    .f = function(x, y) {
      x |>
        left_join(y, by = c("external_id", "counter"))
    }
  ) |> 
  dplyr::mutate(mode_pct = if_else(is.nan(mode_pct), NA, mode_pct)) |> 
  dplyr::rename(k_values = kValues)
```

For now, we also convert longstring and mode proportions to absolute numbers:
```{r}
df_indices <- df_indices |> 
  mutate(longstring_proportion = as.integer(longstring_proportion * length(ema_items)),
         mode_pct = as.integer(mode_pct * length(ema_items)))
```



## Full Analysis
We split the full data set into multiple chunks for easier computation: 
```{r}
# get list of ids
unique_ids <- data |> 
  distinct(external_id) |> 
  pull(external_id)

# create chunk labels
num_per_group <- 50
num_groups <- ceiling(length(unique_ids) / num_per_group)
group_labels <- rep(1:num_groups, each = num_per_group)[seq_along(unique_ids)]

# map external_ids to groups
id_groups <- data.frame(external_id = unique_ids, group = group_labels)
data_grouped <- data |> left_join(id_groups, by = "external_id")

# Split into a list of dataframes, one for each group
data_subsets <- split(data_grouped, data_grouped$group)

df_indices_list <- list()

# Process each chunk
for (i in seq(num_groups)) {
  cat("Processing chunk", i, "of", seq(num_groups), "\n")
  
  # Get the current chunk
  chunk_data <- data_subsets[[i]]
  
  # Calculate indices for the current chunk
  indices <- index_functions |>
    purrr::map(
      .f = function(x) {
        do.call(x$func, c(list(data = chunk_data), x$args))
      }
    )
  
  # Combine indices for the current chunk
  chunk_indices <- indices |>
    purrr::reduce(
      .f = function(x, y) {
        x |>
          left_join(y, by = c("external_id", "counter"))
      }
    ) |>
    dplyr::mutate(mode_pct = if_else(is.nan(mode_pct), NA, mode_pct)) |>
    dplyr::rename(k_values = kValues)
  
  # Convert proportions to absolute numbers
  chunk_indices <- chunk_indices |>
    mutate(longstring_proportion = as.integer(longstring_proportion * length(ema_items)),
           mode_pct = as.integer(mode_pct * length(ema_items)))
  
  # Append the chunk results to the list
  df_indices_list[[i]] <- chunk_indices
}

# Combine all chunk results
df_indices <- df_indices_list |>
  purrr::reduce(
    .f = function(x, y) {
      x |>
        bind_rows(y, .id = "chunk_id")
    }
  )

# save results
saveRDS(df_indices, file = here::here("output", "df_indices.RDS"))
```




# Descriptives & Visualizations

## Summary statistics

Numbers in parentheses represent first and third quartile. 
```{r}
gtsummary::tbl_summary(df_indices,
                       include = !c(external_id, counter),
                       missing_text = "(Missing)") |> 
  gtsummary::as_gt() |> 
  gt::tab_source_note(gt::md("*Only based on a subset of the full sample.*"))
```



## Large grid plot with all indices


kValues seem to be useless, so we filter them out here. Also, we filter out extreme time differences.

We first create a plot for all integer/proportion indices: 
```{r}
# use color based on the Johnson palette from MetBrewer
fill_color <- "#132b69"


# A function factory for getting integer y-axis values.
# (https://gist.github.com/jhrcook/eb7b63cc57c683a6eb4986c4107a88ec)
integer_breaks <- function(n = 5, ...) {
    fxn <- function(x) {
        breaks <- floor(pretty(x, n, ...))
        names(breaks) <- attr(breaks, "labels")
        breaks
    }
    return(fxn)
}

integer_plot <- df_indices |> 
  select(!c(external_id, counter, k_values)) |> 
  select(anto_violations, syno_violations, longstring_proportion, mode_pct) |> 
  rename(
    "Synonym" = "syno_violations", 
    "Antonym" = "anto_violations",
    "Longstring" = "longstring_proportion",
    "Items at Mode" = "mode_pct"
  ) |> 
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |> 
  ggplot(aes(x = value))+
  geom_bar(fill = fill_color)+
  ggh4x::facet_wrap2(.~index, 
                     scales = "free_y",
                     axes = "all")+
  scale_y_continuous(expand = c(0,0))+
  scale_x_continuous(breaks = 0:10)+
  theme_bs()+
  labs(x = "", 
       y = "")

integer_plot
```





Then create a plot for all continuous indices: 
```{r}
cont_plot <- df_indices |> 
  select(!c(external_id, counter, k_values)) |> 
  filter(sd_time_diff < 10) |> 
  select(assessment_sd, mahalanobis_dist, robustpca_dist, sd_time_diff) |> 
  rename(
    "Assessment SD" = "assessment_sd",
    "Mahalanobis" = "mahalanobis_dist",
    "Robust PCA" = "robustpca_dist",
    "Time SD" = "sd_time_diff"
  ) |> 
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |> 
  ggplot(aes(x = value))+
  geom_density(fill = fill_color, color = fill_color,
              # use finer bandwidth
               adjust = 1/4)+
  ggh4x::facet_wrap2(.~index, 
                     scales = "free")+
  scale_y_continuous(expand = c(0,0))+
  theme_bs()+
  labs(x = "", 
       y = "")

cont_plot
```

Combine the plots: 
```{r, warnings = FALSE}
combined_plot <- cowplot::plot_grid(integer_plot, cont_plot, nrow = 2)

ggsave("indices_overview.pdf", 
       plot = combined_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```





# Session Info

```{r session-info}
pander::pander(sessionInfo())

```

