---
title: "Careless Responding"
subtitle: "Calculating Indices"
author: 
 - name: Bj√∂rn S. Siepe
   orcid: 0000-0002-9558-4648
   affiliations: University of Marburg
 - name: Add name(s) of person(s) responsible for respective file
   orcid: 0000-0002-9558-4648
   affiliations: to be added
date: "`r Sys.Date()`"
format:
  html:
    toc: true
    number-sections: true
    theme: cosmo
    code-fold: true
    code-tools: true
    code-summary: "Show the code"
    fig-width: 7
    fig-height: 4.5
    fig-align: "center"
    embed-resources: true
execute:
  message: false
  warning: false
  eval: true # run code?
params:
  rerun: false  # define parameter if all large analyses should be rerun
---

# Background
In this file, we will compute all indices of careless responding. We aim for the following structure: 
`external_id`, `counter`, `index`. There should be no implicit missingness. 

TODOS:

    - We should maybe return 0 for the within-assessment-SD instead of NA when there is no variability at all. 



We first load all relevant packages: 
```{r packages}
if(!require(pacman))
  install.packages("pacman")
pacman::p_load(
  "here",
  "ggplot2",
  "rrcov",
  "Hmisc",
  "sysfonts",
  "showtext",
  "ggh4x",
  "cowplot",
  "gtsummary",
  "gt",
  "future",
  "furrr",
  "dplyr",
  "tidyr",
  "vegan",
  "tibble",
  "purrr"
)


source(here("scripts", "00_functions.R"))

set.seed(35032)  
```


We load the data and remove all non-EMA prompts. Insert your dataset in the subfolder `/data/` and load it here. 
```{r read-data}
#| eval: !expr params$rerun
data <- read.csv(here::here("data", "WARND_stage2_c1234_trainingset_before_30min_v2024_07_16.csv"))

data <- data |> 
  filter(!is.na(counter))
```

Relevant EMA items and their reaction times: 
```{r ema-itemss}
ema_items <-  c("sad_d", "stressed_d", "overwhelm_d", "nervous_d", "ruminate_d", "irritable_d", "cheerful_d", "motivated_d", "relaxed_d")
rt_ema_items <- paste0("rt_", ema_items)

```


For later visualizations, we also load the results of different model-based approaches: 
```{r load-models}
lpa_res <- readRDS(here::here("output", "data_profiles.RDS"))
irt_res <- readRDS(here::here("output", "data_mixtureIRT.RDS"))
```


# Data Preparation

We first subset the data for testing the functions on a smaller dataframe of 30 individuals:

```{r subset-data, eval = FALSE}
#| eval: !expr params$rerun
# select 30 individuals at random
ids_to_subset <- data |> 
  distinct(external_id) |> 
  slice_sample(n = 30) |> 
  pull(external_id)


subset_data <- data |> 
  filter(external_id %in% ids_to_subset)

saveRDS(subset_data, file = here::here("data", "indices_experiment_data.RDS"))

```

```{r, include = FALSE}
subset_data <- readRDS(here::here("data", "indices_experiment_data.RDS"))
```



# Analysis

Currently, this depends on `sd_within_assessment` being the first, to have no implicit missingness when using `left_join()` later below.
```{r}
# Define the functions and their parameters
index_functions <- list(
    sd_within_assessment = list(
    func = calc_within_assessment_sd,
    args = list(
      items = ema_items,
      id_col = "external_id"
    )
  ),
  mahalanobis = list(
    func = calc_indicator_mahalanobis,
    args = list(items = ema_items)
  ),
  robust_pca = list(
    func = calc_indicator_rob_PCA_orthogonal_distance,
    args = list(items = ema_items)
  ),
  # leave out synonym for now
  # psychometric_syntonym = list(
  #   func = calc_psychometric_synonym_violations,
  #   args = list(
  #     items = ema_items,
  #     cor_threshold = 0.45,
  #     synonym_difference_threshold = 5
  #   )
  # ),
  psychometric_antonym = list(
    func = calc_psychometric_antonym_violations,
    args = list(
      items = ema_items,
      antonym_pair = c("stressed_d", "relaxed_d"),
      # cor_threshold = 0.45,
      antonym_maxvalue_threshold = 4
    )
  ),
  mean_response_times = list(
    func = calc_summary_response_times,
    args = list(items = rt_ema_items, summary = "mean")
  ),
  sd_response_times = list(
    func = calc_summary_response_times,
    args = list(items = rt_ema_items, summary = "sd")
  ),

  items_at_mode = list(
    func = calc_mode_percentage,
    args = list(
      items = ema_items,
      id_col = "external_id"
    )
  ),
  longstring = list(
    func = calc_longstring_counts, 
    args = list(
      items = ema_items, 
      rt_items = rt_ema_items
    )
  )
)


```


Calculate them all on the subset:

```{r calc-indices, message=FALSE}
#| eval: !expr params$rerun
# calculate all indices
indices <- index_functions |>
  purrr::map(
    .f = function(x) {
      do.call(x$func, c(list(data = subset_data), x$args))
    }
  )

# combine indices
df_indices <- indices |>
  purrr::reduce(
    .f = function(x, y) {
      x |>
        left_join(y, by = c("external_id", "counter"))
    }
  ) |> 
  dplyr::mutate(mode_count = if_else(is.nan(mode_count), NA, mode_count)) |> 
  dplyr::rename(k_values = kValues)
```

For now, we also convert longstring and mode proportions to absolute numbers:
```{r}
#| eval: !expr params$rerun
df_indices <- df_indices |> 
  mutate(longstring_count = as.integer(longstring_count * length(ema_items)),
         mode_count = as.integer(mode_count * length(ema_items)))
```



## Full Analysis Individual Indices
We split the full data set into multiple chunks for easier computation: 
```{r}
#| eval: !expr params$rerun
# get list of ids
unique_ids <- data |> 
  distinct(external_id) |> 
  pull(external_id)

# create chunk labels
num_per_group <- 50
num_groups <- ceiling(length(unique_ids) / num_per_group)
group_labels <- rep(1:num_groups, each = num_per_group)[seq_along(unique_ids)]

# map external_ids to groups
id_groups <- data.frame(external_id = unique_ids, group = group_labels)
data_grouped <- data |> left_join(id_groups, by = "external_id")

# Split into a list of dataframes, one for each group
data_subsets <- split(data_grouped, data_grouped$group)

df_indices_list <- list()

time_before <- Sys.time()


# Process each chunk
for (i in seq(num_groups)) {
  cat("Processing chunk", i, "of", num_groups, "\n")

  # Get the current chunk
  chunk_data <- data_subsets[[i]]

  # Calculate indices for the current chunk
  indices <- index_functions |>
    purrr::map(
      .f = function(x) {
        do.call(x$func, c(list(data = chunk_data), x$args))
      }
    )

  # Combine indices for the current chunk
  chunk_indices <- indices |>
    purrr::reduce(
      .f = function(x, y) {
        x |>
          left_join(y, by = c("external_id", "counter"))
      }
    ) |>
    dplyr::mutate(mode_count = if_else(is.nan(mode_count), NA, mode_count)) |>
    dplyr::rename(k_values = kValues)

  # Convert proportions to absolute numbers
  chunk_indices <- chunk_indices |>
    mutate(longstring_count = as.integer(longstring_count * length(ema_items)),
           mode_count = as.integer(mode_count * length(ema_items)))

  # Append the chunk results to the list
  df_indices_list[[i]] <- chunk_indices
}

time_diff <- Sys.time() - time_before
# ~30mins.

# Combine all chunk results
df_indices <- df_indices_list |>
  purrr::reduce(
    .f = function(x, y) {
      x |>
        bind_rows(y, .id = "chunk_id")
    }
  ) |> 
  select(-chunk_id) |> 
  arrange(external_id, counter)

# save results
saveRDS(df_indices, file = here::here("output", "df_indices.RDS"))
```

Read back in: 
```{r}
df_indices <- readRDS(file = here::here("output", "df_indices.RDS"))
```


For the robust PCA, we used the default settings of the `rrcov` R package with a maximum number of nine principal components, corresponding to the number of items used.

# Multiverse Indices

Here, we investigate different settings to detect careless responding. These concern: 
1. Different cutoffs and settings for individual indices
2. Different combination rules for multiple indices

We define a grid of different cutoffs and settings. 

```{r specifications}
sd_within_cutoff <- c(0.75, 1, 1.25)
average_response_time_cutoff <- c(1, 1.5, 2)
sd_response_time_cutoff <- c(0.4, 0.6, 1)
longstring_cutoff <- c(6, 7, 8)
mode_cutoff <- c(5, 6)

specification_grid <- expand.grid(
  sd_within_cutoff, 
  average_response_time_cutoff, 
  sd_response_time_cutoff,
  longstring_cutoff,
  mode_cutoff
)

colnames(specification_grid) <- 
  c(
  "sd_within_cutoff", 
  "average_response_time_cutoff", 
  "sd_response_time_cutoff", 
  "longstring_cutoff", 
  "mode_cutoff"
)



```

We then compute the multiverse by flagging each index at each observation as being indicative of careless responding or not:
```{r flag-careless}
#| eval: !expr params$rerun
# flagging response as careless
flag_careless <- function(df, cutoffs) {
  df |>
    mutate(
      flag_sd_within = assessment_sd < cutoffs$sd_within_cutoff,
      flag_average_response_time = average_response_time < cutoffs$average_response_time_cutoff,
      flag_sd_response_time = sd_response_time < cutoffs$sd_response_time_cutoff,
      flag_longstring = longstring_count > cutoffs$longstring_cutoff,
      flag_mode = mode_count > cutoffs$mode_cutoff
    ) |>
    mutate(spec_id = paste0("spec_", "sd_", cutoffs$sd_within_cutoff, "_",
                                    "avg_rt_",  cutoffs$average_response_time_cutoff, "_",
                                    "sd_rt_",  cutoffs$sd_response_time_cutoff, "_",
                                    "long_",  cutoffs$longstring_cutoff, "_",
                                    "mode_",  cutoffs$mode_cutoff))
}

careless_results_list <- purrr::pmap(specification_grid, function(sd_within_cutoff, average_response_time_cutoff,
                                                  sd_response_time_cutoff, longstring_cutoff, mode_cutoff) {
  cutoffs <- list(
    sd_within_cutoff = sd_within_cutoff,
    average_response_time_cutoff = average_response_time_cutoff,
    sd_response_time_cutoff = sd_response_time_cutoff,
    longstring_cutoff = longstring_cutoff,
    mode_cutoff = mode_cutoff
  )
  flag_careless(df_indices, cutoffs)
})


saveRDS(careless_results_list, file = here::here("output", "careless_results_list.RDS"))
```

Reload the dataframe:
```{r reload-careless}
careless_results_list <- readRDS(here::here("output", "careless_results_list.RDS"))
df_careless <- bind_rows(careless_results_list)
```


We can then apply different combination rules for multiple indices. For the manuscript, we focus on our "main" specification, which is:

    - Within-assessment variability: 1.0
    - Longstring: 7/9
    - Mode: 5/9
    - Average response time: 1.5s
    - SD response time: 0.6s
    
```{r multiple-hurdles}
# select df of main specification
main_id <- specification_grid |>
  mutate(id = row_number()) |> 
  filter(
    sd_within_cutoff == 1.0 &
      average_response_time_cutoff == 1.5 &
      sd_response_time_cutoff == 0.6 &
      longstring_cutoff == 7 & mode_cutoff == 5
  ) |> 
    pull(id)


main_df <- careless_results_list[[main_id]]

# apply multiple hurdle approach
flag_df <- main_df |> 
  dplyr::select(external_id, counter, starts_with("flag")) |> 
  rowwise() |> 
  mutate(flag_sum = sum(flag_sd_within, flag_average_response_time, flag_sd_response_time, flag_longstring, flag_mode, na.rm = TRUE)) 



```



# Descriptives & Visualizations

## Summary statistics


Numbers in parentheses represent first and third quartile. 
```{r}
df_indices |>   
  mutate(k_values = as.factor(k_values), 
         # syno_violations = as.factor(syno_violations), 
         anto_violations = as.factor(anto_violations), 
         longstring_count = as.factor(longstring_count)) |> 
  gtsummary::tbl_summary(include = !c(external_id, counter),
                       missing_text = "(Missing)") |> 
  gtsummary::as_gt()
```





## Large grid plot with all indices


kValues seem to be useless, so we filter them out here. Also, we filter out extreme time differences.

We first create a plot for all integer/proportion indices: 
```{r}
# use color based on the Johnson palette from MetBrewer
fill_color <- "#132b69"


# A function factory for getting integer y-axis values.
# (https://gist.github.com/jhrcook/eb7b63cc57c683a6eb4986c4107a88ec)
integer_breaks <- function(n = 5, ...) {
    fxn <- function(x) {
        breaks <- floor(pretty(x, n, ...))
        names(breaks) <- attr(breaks, "labels")
        breaks
    }
    return(fxn)
}

integer_plot <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  dplyr::select(anto_violations,
         # syno_violations,
         longstring_count,
         mode_count) |>
  rename(
    # "Synonym" = "syno_violations",
    "Antonym" = "anto_violations",
    "Longstring" = "longstring_count",
    "Items at Mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value)) +
  geom_bar(fill = fill_color) +
  ggh4x::facet_wrap2(. ~ index, scales = "free_y", axes = "all") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(breaks = 0:10) +
  theme_bs() +
  labs(x = "", y = "")
```

Alternatively, convert the plot to percentages: 
```{r}
integer_plot_pct <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  dplyr::select(anto_violations,
         # syno_violations,
         longstring_count,
         mode_count) |>
  rename(
    # "Synonym" = "syno_violations",
    "Antonym" = "anto_violations",
    "Longstring" = "longstring_count",
    "Items at Mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value, y = after_stat(prop))) +  # for percentage
  geom_bar(fill = fill_color) +
  ggh4x::facet_wrap2(. ~ index, scales = "free_y", axes = "all") +
  scale_y_continuous(expand = c(0, 0), labels = scales::percent_format()) +
  scale_x_continuous(
    breaks = 0:11,
    expand = c(0, 0),
    limits = c(-.6, 11.1)
  ) +
  theme_bs() +
  labs(x = "", y = "Percentage")
integer_plot_pct
```



Then create a plot for all continuous indices: 
```{r}
cont_plot <- df_indices |>
  dplyr::select(!c(external_id, counter, k_values)) |>
  filter(sd_response_time < 10) |>
  dplyr::select(assessment_sd,
         mahalanobis_dist,
         robustpca_dist,
         average_response_time,
         sd_response_time,
  ) |>
  rename(
    "Assessment SD" = "assessment_sd",
    "Mahalanobis" = "mahalanobis_dist",
    "Robust PCA" = "robustpca_dist",
    "Average RT" = "average_response_time",
    "SD RT" = "sd_response_time"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value)) |>
  ggplot(aes(x = value)) +
  geom_density(fill = fill_color,
               color = fill_color,
               # use finer bandwidth
               adjust = 1 / 4) +
  ggh4x::facet_wrap2(. ~ index, scales = "free") +
  scale_y_continuous(expand = c(0, 0)) +
  theme_bs() +
  labs(x = "", y = "")

cont_plot
```

Combine the plots: 
```{r, warnings = FALSE}
combined_plot <- cowplot::plot_grid(integer_plot_pct, cont_plot, nrow = 2)

ggsave("indices_overview.pdf", 
       plot = combined_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```



# Similarity Indices and Models

We attach the model results to the indices. We classify everyone with an LPA profile 1 or 2, and a mixture IRT class 1 as attentive. 
```{r attach-model}
df_indices_models <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |> 
  left_join(flag_df, by = c("external_id", "counter")) |> 
    mutate(across(where(is.logical), ~ as.integer(.))) |> 
    mutate(flag_lpa = ifelse(LPA_profile <= 2, 0, 1),
           flag_irt = ifelse(mixtureIRT == 1, 0, 1)) |> 
   select(contains("flag")) |> 
  # remove multiple hurdle as it is not binary
  select(!flag_sum) 
  
```


## Large grid plot with indicators and model results

Create distribution plot for the LPA and mixture IRT: 

```{r model-distributions}
lpa_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  count(LPA_profile) |> 
  mutate(percent = n / sum(n))

# plot LPA results
lpa_dist_plot <- lpa_prop_df |> 
  ggplot(aes(x = as.factor(LPA_profile), y = percent, fill = as.factor(LPA_profile))) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_viridis_d() +
  scale_y_continuous(limits = c(0, .45), expand = c(0, 0), labels = scales::percent_format()) +
  theme_bs() +
  labs(x = "Profile Membership", 
       y = "",
       title = "Latent Profile")

lpa_dist_plot  

ggsave("lpa_descriptive_plot.pdf", 
       plot = lpa_dist_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```

Plot mixture IRT class membership overall:
```{r}
irt_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  count(mixtureIRT) |> 
  mutate(percent = n / sum(n)) |> 
  filter(!is.na(mixtureIRT))

# plot irt results
irt_dist_plot <- irt_prop_df |>
  ggplot(aes(
    x = as.factor(mixtureIRT),
    y = percent,
    fill = as.factor(mixtureIRT)
  )) +
  geom_bar(stat = "identity", show.legend = FALSE) +
  scale_fill_viridis_d() +
  scale_y_continuous(
    limits = c(0, 1.05),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  theme_bs() +
  labs(x = "Mixture IRT Class", y = "Percentage of Participants")

irt_dist_plot  

ggsave("irt_descriptive_plot.pdf", 
       plot = irt_dist_plot, 
       path = here::here("figures"),
       height = 10, 
       width = 8)
```

Plot mixture IRT class membership by calculating how often each individual was classified as being in the inattentive state:

```{r}
irt_prop_df <- lpa_res |> 
  left_join(irt_res, by = c("external_id", "counter")) |>
  left_join(flag_df, by = c("external_id", "counter")) |> 
  mutate(across(where(is.logical), ~ as.integer(.))) |> 
  filter(!is.na(mixtureIRT)) |> 
  group_by(external_id) |> 
  summarise(n_careless = sum(mixtureIRT == 2, na.rm = TRUE)) |> 
  ungroup()

# summarize how many participants had X number of careless time points
irt_summary_df <- irt_prop_df |> 
  count(n_careless) |> 
  mutate(percent = n / sum(n))

# plot
irt_dist_plot_timepoints <- irt_summary_df |> 
  ggplot(aes(x = n_careless, y = percent)) +
  geom_bar(stat = "identity", show.legend = FALSE, fill = fill_color) +
  scale_y_continuous(
    limits = c(0, .25),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  scale_x_continuous(
    breaks = scales::pretty_breaks(),
    expand = c(0, 0)
  ) +
  theme_bs() +
  labs(
    x = "Number of Careless Time Points",
    # y = "Percentage of Participants"
  )

irt_dist_plot_timepoints

```

Alternatively, we can bin the number of careless time points:
```{r}
# bin careless counts
irt_binned_df <- irt_prop_df |> 
  mutate(
    careless_bin = cut(
      n_careless,
      breaks = c(-Inf, 0, 5, 10, 20, 50, Inf),
      labels = c("0", "1‚Äì5", "6‚Äì10", "11‚Äì20", "21‚Äì50", "51+"),
      right = TRUE
    )
  )

# summarize number of participants in each bin
irt_summary_df <- irt_binned_df |> 
  count(careless_bin) |> 
  mutate(percent = n / sum(n))

# plot
irt_dist_plot_binned <- irt_summary_df |> 
  ggplot(aes(x = careless_bin, y = percent)) +
  geom_bar(stat = "identity", show.legend = FALSE, fill = fill_color) +
  scale_y_continuous(
    limits = c(0, .45),
    expand = c(0, 0),
    labels = scales::percent_format()
  ) +
  # scale_fill_viridis_d() +
  theme_bs() +
  labs(
    x = "N¬∞ of Careless Time Points",
    y = "",
    title = "Mixture IRT"
  )
  # theme(
  #   axis.text.x = element_text(size = 15)
  # )

irt_dist_plot_binned
```


Now combine these plots with all individual indices plots:
```{r giga-plot}
# Create individual plots for each index
df_integer_long <- df_indices |>
  select(!c(external_id, counter, k_values)) |>
  select(
    anto_violations,
    # syno_violations,
    longstring_count,
    mode_count
  ) |>
  rename(
    "Likelihood of antonym violation" = "anto_violations",
    "Long string count" = "longstring_count",
    "Items that fall at the mode" = "mode_count"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value))

# create list of individual bar plots
integer_plot_list <- df_integer_long |>
  group_split(index) |>
  map(~ {
    index_label <- unique(.x$index)

    p <- ggplot(.x, aes(x = value, y = after_stat(prop))) +
      geom_bar(fill = fill_color) +
      scale_y_continuous(expand = c(0, 0), labels = scales::percent_format()) +
      theme_bs() +
      labs(x = "", y = "") +
      ggtitle(index_label)

    # customize x-axis for the antonym violation (binary) plot
    if (index_label == "Likelihood of antonym violation") {
      p <- p + scale_x_continuous(
        breaks = c(0, 1),
        limits = c(-0.5, 1.5),
        expand = c(0, 0)
      )
    } else {
      p <- p + scale_x_continuous(
        breaks = 0:11,
        limits = c(-0.6, 11.1),
        expand = c(0, 0)
      )
    }

    p
  })

# create list of individual density plots
df_cont_long <- df_indices |>
  select(!c(external_id, counter, k_values)) |>
  filter(sd_response_time < 10) |>
  select(
    assessment_sd,
    mahalanobis_dist,
    robustpca_dist,
    average_response_time,
    sd_response_time
  ) |>
  rename(
    "Within-assessment response SD" = "assessment_sd",
    "Mahalanobis dstance" = "mahalanobis_dist",
    "Robust PCA distance" = "robustpca_dist",
    "Average time-per-item" = "average_response_time",
    "SD time-per-item" = "sd_response_time"
  ) |>
  pivot_longer(cols = everything(), names_to = "index") |>
  filter(!is.na(value))


cont_plot_list <- df_cont_long |>
  group_split(index) |>
  map(~ {
    ggplot(.x, aes(x = value)) +
      geom_density(fill = fill_color, color = fill_color, adjust = 1 / 4) +
      scale_y_continuous(expand = c(0, 0)) +
      theme_bs() +
      labs(x = "", y = "") +
      ggtitle(unique(.x$index))
  })

# combine into grid
plot_grid_list <- c(integer_plot_list, cont_plot_list, list(lpa_dist_plot, irt_dist_plot_binned))

combined_plot_all <- cowplot::plot_grid(
  plotlist = plot_grid_list,
  ncol = 2,  
  align = "hv"
)

ggsave("indices_models_overview.pdf", 
       plot = combined_plot_all, 
       path = here::here("figures"),
       height = 16, 
       width = 11)
```






## Jaccard Similarity of Indices and Model Results

We can visualize the classification of careless responding based on indices and and model results with a Jaccard similarity heatmap. 

```{r jaccard-similarity}
jaccard_matrix <- vegan::vegdist(t(df_indices_models), na.rm = TRUE, method = "jaccard", binary = TRUE)
jaccard_matrix <- as.matrix(jaccard_matrix)

# convert dissimilarity to similarity
jaccard_sim_matrix <- 1-jaccard_matrix

# self-similarity
diag(jaccard_sim_matrix) <- 1

jaccard_sim_matrix |> 
  as.data.frame() |> 
  rownames_to_column(var = "Var1") |> 
  pivot_longer(-Var1, names_to = "Var2", values_to = "Similarity") |> 
  ggplot(aes(x = Var1, y = Var2, fill = Similarity)) +
  geom_tile(color = "white") + 
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0.5, limit = c(0,1), space = "Lab",
                       name="Jaccard\nSimilarity") +
  theme_bs() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), 
        axis.title.x = element_blank(), 
        axis.title.y = element_blank(), 
        panel.grid.major = element_blank(), 
        panel.border = element_blank(),
        legend.justification = c(1, 0),
        legend.position = c(0.6, 0.7), 
        legend.direction = "horizontal") +
  coord_fixed() + 
  geom_text(aes(label = round(Similarity, 2)), color = "black", size = 3)

```



# Session Info

```{r session-info}
pander::pander(sessionInfo())

```

